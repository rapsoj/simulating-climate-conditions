import requests
from bs4 import BeautifulSoup
import pandas as pd
from io import StringIO

# URL of the Worldometer coal consumption data page
url = 'https://www.worldometers.info/coal/coal-consumption-by-country/'

# Send a GET request to the URL
response = requests.get(url)

if response.status_code == 200:
    # Parse the HTML content of the page with BeautifulSoup
    soup = BeautifulSoup(response.text, 'html.parser')
    table = soup.find('table')
    
    if table:
        # Convert the HTML table to a pandas DataFrame
        html_content = str(table)  # Convert table to string
        df = pd.read_html(StringIO(html_content))[0]  # Use StringIO here

        # Rename the DataFrame columns appropriately
        df.columns = ['Rank', 'Country', 'Coal Consumption (tonnes)', 'World Share', 'Consumption Per Capita (cubic feet)']

        # Sort the DataFrame by 'Country' column in alphabetical order
        df = df.sort_values('Country')

        # Save the DataFrame to a CSV file
        path = '/Users/apple/Desktop/Coal_Consumption_by_Country.csv'
        df.to_csv(path, index=False)
        print(f"CSV file has been saved to {path} sorted alphabetically by country.")
    else:
        print("Table not found in the HTML.")
else:
    print("Failed to retrieve the page. Status Code:", response.status_code)
